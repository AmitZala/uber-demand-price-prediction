# ğŸš• Uber Demand Prediction in New York City

A machine learning project that predicts taxi demand across 30 regions in New York City using historical trip data. The project includes a complete MLOps pipeline with data processing, feature engineering, model training, and an interactive Streamlit web application for real-time demand visualization.

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/streamlit-1.39.0-red.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.6.1-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Model Details](#model-details)
- [Data Pipeline](#data-pipeline)
- [Streamlit App](#streamlit-app)
- [MLOps Integration](#mlops-integration)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)
- [Author](#author)

## ğŸ¯ Overview

This project predicts taxi demand for the next 15-minute interval across 30 distinct regions in New York City. The solution uses:

- **Clustering**: MiniBatch K-Means to divide NYC into 30 regions based on pickup locations
- **Time Series Features**: Lag features and temporal patterns (day of week, month)
- **Smoothing**: Exponential Weighted Moving Average (EWMA) for demand smoothing
- **Regression Model**: Linear Regression for demand prediction
- **Interactive Dashboard**: Streamlit app for real-time demand visualization

## âœ¨ Features

- ğŸ—ºï¸ **Geographic Clustering**: Automatically divides NYC into 30 regions using K-Means clustering
- ğŸ“Š **Time Series Analysis**: Captures temporal patterns with lag features and datetime features
- ğŸ¨ **Interactive Dashboard**: Beautiful Streamlit app with map visualization
- ğŸ”„ **MLOps Pipeline**: Complete DVC pipeline for reproducible experiments
- ğŸ“ˆ **Model Tracking**: MLflow integration via DagsHub for experiment tracking
- ğŸš€ **Production Ready**: Trained models ready for deployment
- ğŸ“± **Real-time Predictions**: Predict demand for any date/time in March 2016

## ğŸ› ï¸ Tech Stack

### Core Technologies
- **Python 3.10+**
- **Pandas** - Data manipulation and analysis
- **NumPy** - Numerical computing
- **scikit-learn** - Machine learning models and preprocessing
- **Streamlit** - Interactive web application

### MLOps & Data Versioning
- **DVC** - Data version control and pipeline management
- **MLflow** - Experiment tracking and model registry
- **DagsHub** - MLflow tracking server

### Data Processing
- **Dask** - Parallel computing for large datasets
- **Joblib** - Model serialization

## ğŸ“ Project Structure

```
uber-demand-price-prediction/
â”‚
â”œâ”€â”€ app.py                      # Streamlit web application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ params.yaml                 # Model hyperparameters
â”œâ”€â”€ dvc.yaml                    # DVC pipeline configuration
â”œâ”€â”€ Makefile                    # Make commands for common tasks
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original, immutable data
â”‚   â”‚   â”œâ”€â”€ yellow_tripdata_2016-01.csv
â”‚   â”‚   â”œâ”€â”€ yellow_tripdata_2016-02.csv
â”‚   â”‚   â””â”€â”€ yellow_tripdata_2016-03.csv
â”‚   â”œâ”€â”€ interim/                # Intermediate data
â”‚   â”‚   â””â”€â”€ df_without_outliers.csv
â”‚   â””â”€â”€ processed/               # Final datasets
â”‚       â”œâ”€â”€ train.csv
â”‚       â”œâ”€â”€ test.csv
â”‚       â””â”€â”€ resampled_data.csv
â”‚
â”œâ”€â”€ models/                     # Trained models
â”‚   â”œâ”€â”€ model.joblib            # Linear Regression model
â”‚   â”œâ”€â”€ encoder.joblib          # Feature encoder
â”‚   â”œâ”€â”€ scaler.joblib           # StandardScaler
â”‚   â””â”€â”€ mb_kmeans.joblib        # K-Means clustering model
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA
â”‚   â”œâ”€â”€ EDA-Demand-Prediction.ipynb
â”‚   â”œâ”€â”€ Breaking_NYC_to_Regions.ipynb
â”‚   â”œâ”€â”€ Creating-Historical-Data.ipynb
â”‚   â”œâ”€â”€ Training-Baseline-Model.ipynb
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data_ingestion.py   # Data loading and preprocessing
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ extract_features.py # Feature extraction & clustering
â”‚   â”‚   â””â”€â”€ feature_processing.py # Lag features & time series
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ train.py            # Model training
â”‚       â”œâ”€â”€ evaluate.py         # Model evaluation
â”‚       â””â”€â”€ register_model.py   # MLflow model registration
â”‚
â””â”€â”€ docs/                       # Documentation
```

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- Git
- (Optional) DVC for pipeline execution

### Step 1: Clone the Repository

```bash
git clone https://github.com/AmitZala/uber-demand-price-prediction.git
cd uber-demand-price-prediction
```

### Step 2: Create Virtual Environment

```bash
# Using venv
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate

# Or using conda
conda create -n uber-demand python=3.10
conda activate uber-demand
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: (Optional) Install DVC

If you want to run the full pipeline:

```bash
pip install dvc
```

## ğŸ’» Usage

### Running the Streamlit App

The easiest way to use the project is through the interactive Streamlit dashboard:

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

**Features of the App:**
- Select date and time (March 2016)
- View your current location on the map
- See demand predictions for all 30 regions
- Filter to view only neighborhood regions
- Interactive map with color-coded regions

### Running the Full Pipeline

If you want to retrain the models from scratch:

```bash
# Install DVC first
pip install dvc

# Run the complete pipeline
dvc repro
```

This will execute all stages:
1. **Data Ingestion**: Load and clean raw data
2. **Extract Features**: Create regions using K-Means, apply EWMA smoothing
3. **Feature Processing**: Generate lag features and split train/test
4. **Train**: Train the Linear Regression model
5. **Evaluate**: Evaluate model performance
6. **Register Model**: Register model in MLflow

### Individual Pipeline Stages

You can also run individual stages:

```bash
# Data ingestion
python src/data/data_ingestion.py

# Feature extraction
python src/features/extract_features.py

# Feature processing
python src/features/feature_processing.py

# Model training
python src/models/train.py

# Model evaluation
python src/models/evaluate.py
```

## ğŸ¤– Model Details

### Architecture

1. **Geographic Clustering**
   - Method: MiniBatch K-Means
   - Number of clusters: 30 regions
   - Features: Scaled pickup coordinates (longitude, latitude)
   - Purpose: Divide NYC into distinct demand regions

2. **Feature Engineering**
   - **Lag Features**: Previous 1-4 time intervals (15-min windows)
   - **Temporal Features**: Day of week, month
   - **Smoothing**: EWMA with alpha=0.4 for average pickups
   - **Encoding**: One-hot encoding for categorical features

3. **Model**
   - Algorithm: Linear Regression
   - Input: Lag features + temporal features + region + day_of_week
   - Output: Predicted number of pickups for next 15-minute interval

### Hyperparameters

See `params.yaml`:
```yaml
extract_features:
  mini_batch_kmeans:
    n_clusters: 30
    n_init: 10
    random_state: 42
  ewma:
    alpha: 0.4
```

## ğŸ”„ Data Pipeline

The project uses DVC for pipeline orchestration:

```
Raw Data â†’ Data Ingestion â†’ Feature Extraction â†’ Feature Processing â†’ Training â†’ Evaluation
```

### Pipeline Stages

1. **data_ingestion**: Cleans raw taxi data, removes outliers
2. **extract_features**: Creates regions, applies EWMA smoothing
3. **feature_processing**: Generates lag features, splits data
4. **train**: Trains Linear Regression model
5. **evaluate**: Evaluates model on test set
6. **register_model**: Registers model in MLflow

## ğŸ¨ Streamlit App

The interactive dashboard (`app.py`) provides:

- **Date/Time Selection**: Choose any date/time in March 2016
- **Location Sampling**: Randomly samples a location from NYC
- **Map Visualization**: 
  - Complete NYC map with all 30 regions
  - Neighborhood view showing 9 nearest regions
- **Demand Predictions**: Real-time predictions for each region
- **Color-coded Regions**: Visual representation of demand levels

### App Features

- Interactive map with Streamlit's native map component
- Real-time demand predictions
- Region-based filtering
- Beautiful UI with progress indicators

## ğŸ“Š MLOps Integration

### MLflow Tracking

The project integrates with MLflow via DagsHub:

- **Tracking URI**: `https://dagshub.com/AmitZala/uber-demand-price-prediction.mlflow`
- **Model Registry**: Models are registered with versioning
- **Experiment Tracking**: All runs are logged with metrics

### DVC Pipeline

- **Reproducibility**: All pipeline stages are versioned
- **Dependency Tracking**: Automatic dependency resolution
- **Parameter Management**: Hyperparameters in `params.yaml`

## ğŸ“ˆ Results

Model performance metrics are saved in `run_information.json` after evaluation. The model predicts demand for 30 regions across NYC with temporal patterns captured through lag features.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Amit Zala**

- GitHub: [@AmitZala](https://github.com/AmitZala)
- DagsHub: [uber-demand-price-prediction](https://dagshub.com/AmitZala/uber-demand-price-prediction)

## ğŸ™ Acknowledgments

- NYC Taxi & Limousine Commission for the dataset
- CookieCutter Data Science project template
- Streamlit for the amazing framework
- DagsHub for MLflow hosting

---

â­ If you find this project helpful, please give it a star!
